{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "d164pghKr7bo",
        "7oUTi5SBjgIX",
        "Cyeb1-3clLBw",
        "GlT3zG0dlSkd",
        "D6sCPdqGlotL",
        "P5FO-tL0GIiD",
        "em6cvrbwGzGt"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning for Medical Imaging\n",
        "## Challenge 2024: Lymphocytosis classification\n",
        "\n",
        "Kelthoum KERBOUA: kelthoum.kerboua@telecom-paris.fr\n",
        "\n",
        "Fatima BALDE: fatima.balde@telecom-paris.fr"
      ],
      "metadata": {
        "id": "S8YSxxE8iXR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries and Load dataset"
      ],
      "metadata": {
        "id": "0EMl0g5li9Cq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fytk5di2tdcZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score,accuracy_score\n",
        "\n",
        "#!pip install segmentation_models_pytorch\n",
        "#import segmentation_models_pytorch as smp\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pickle\n",
        "from datetime import datetime, date\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used google collab with T4 GPU."
      ],
      "metadata": {
        "id": "PmlX9C0AjB3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = 'cuda' if cuda else 'cpu'"
      ],
      "metadata": {
        "id": "dRxSZNFXwJph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is compressed in the google drive. The following lines of code load the data."
      ],
      "metadata": {
        "id": "CwJFcEAmjMu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1XpTZ3Lt96P",
        "outputId": "7a0cc2b4-0210-4c6a-9c81-cf932f8d5e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"./drive/MyDrive/dlmi-lymphocytosis-classification.zip\"\n",
        "directory='dlmi-lymphocytosis-classification'"
      ],
      "metadata": {
        "id": "4_8PnVMIuAZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ],
      "metadata": {
        "id": "d164pghKr7bo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing"
      ],
      "metadata": {
        "id": "7oUTi5SBjgIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We store the blood smears for each patient in a list and calculate their age."
      ],
      "metadata": {
        "id": "_ekNFanZjnWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory='dlmi-lymphocytosis-classification'\n",
        "training_data = pd.read_csv('dlmi-lymphocytosis-classification/trainset/trainset_true.csv')\n",
        "training_data['IMAGES'] = None\n",
        "training_data['YOB'] = pd.DatetimeIndex(training_data['DOB']).year\n",
        "training_data['MOB'] = pd.DatetimeIndex(training_data['DOB']).month\n",
        "training_data['DOB']=pd.to_datetime(training_data['DOB'])\n",
        "current_date = datetime.now()\n",
        "training_data['AGE'] = (current_date - training_data['DOB']).astype('<m8[Y]')\n",
        "\n",
        "\n",
        "for i, row in tqdm(training_data.iterrows(), total=len(training_data)):\n",
        "    list_paths = glob.glob(f'dlmi-lymphocytosis-classification/trainset/{row[\"ID\"]}/*.jpg')\n",
        "    list_images = [cv2.imread(path) for path in list_paths]\n",
        "    training_data.at[i, 'IMAGES'] = list_images\n",
        "\n",
        "test_data = pd.read_csv(directory +'/testset/testset_data.csv')\n",
        "test_data['IMAGES'] = None\n",
        "test_data['YOB'] = pd.DatetimeIndex(test_data['DOB']).year\n",
        "test_data['MOB'] = pd.DatetimeIndex(test_data['DOB']).month\n",
        "test_data['DOB']=pd.to_datetime(test_data['DOB'])\n",
        "test_data['AGE'] = (current_date - test_data['DOB']).astype('<m8[Y]')\n",
        "\n",
        "\n",
        "test_IDs=[]\n",
        "for i, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
        "    list_paths = glob.glob(f'dlmi-lymphocytosis-classification/testset/{row[\"ID\"]}/*.jpg')\n",
        "    test_IDs.append(row[\"ID\"])\n",
        "    list_images = [cv2.imread(path) for path in list_paths]\n",
        "    test_data.at[i, 'IMAGES'] = list_images"
      ],
      "metadata": {
        "id": "ils6wFvkwSF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32dc759-d8cf-4d99-9cc6-8ddef80a632f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [00:13<00:00, 12.49it/s]\n",
            "100%|██████████| 42/42 [00:02<00:00, 14.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a MILDataset which returns the list of images (blood smears), clinical attributes and label for each patient."
      ],
      "metadata": {
        "id": "wRdY98SIj09y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MILDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, transform=transforms.ToTensor()):\n",
        "        super().__init__()\n",
        "\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        images = [self.transform(image) for image in row['IMAGES']]\n",
        "        images = torch.stack(images, 0)\n",
        "        label = row['LABEL']\n",
        "        clinical = np.array([row['MOB'], row['YOB'], row['AGE'], row['LYMPH_COUNT']])\n",
        "        return images, clinical, label"
      ],
      "metadata": {
        "id": "Hx8sO0pWyc40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a collate_fn function that concatenates the lists of blood smears and shuffles them, while remembering the index of their bags (patient) and their place in the bag."
      ],
      "metadata": {
        "id": "-30FJpcOkDW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(inputs):\n",
        "    images, clinical, labels = zip(*inputs)\n",
        "    indices_of_bags = torch.cat([i*torch.ones(len(images[i]), dtype=torch.long) for i in range(len(images))])\n",
        "    # indices_of_bags = patient index\n",
        "    indices_in_bags = torch.cat([torch.arange(len(images[i]), dtype=torch.long) for i in range(len(images))])\n",
        "    # indices_in_bags = image index in patient's blood smears list\n",
        "    images = torch.cat(images, 0)\n",
        "    permutation = torch.randperm(len(images))\n",
        "    images = images[permutation]\n",
        "    indices_in_bags = indices_in_bags[permutation]\n",
        "    indices_of_bags = indices_of_bags[permutation]\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "    clinical = torch.tensor(clinical, dtype=torch.float)\n",
        "    return images, clinical, labels, indices_of_bags, indices_in_bags"
      ],
      "metadata": {
        "id": "xqGYFUzlyN9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We divide the dataset into a train and a validation set (50%/50%), keeping the same proportion of labels. We define data augmentation techniques for the training set. Pre-processing steps are defined for all images (crop image to size 112x112, normalization, transformation to tensor torch)."
      ],
      "metadata": {
        "id": "FpkoysLdkqsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.RandomRotation(degrees=(0, 180)),\n",
        "    torchvision.transforms.CenterCrop(112),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.tensor([0.8183, 0.6977, 0.7034]), torch.tensor([0.1917, 0.2156, 0.0917])),\n",
        "])\n",
        "\n",
        "test_transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToPILImage(),\n",
        "    torchvision.transforms.CenterCrop(112),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(torch.tensor([0.8183, 0.6977, 0.7034]), torch.tensor([0.1917, 0.2156, 0.0917])),\n",
        "])\n",
        "\n",
        "train_data, valid_data = train_test_split(training_data, test_size=0.5, stratify= training_data['LABEL'], random_state=1)\n",
        "\n",
        "train_dataset = MILDataset(train_data, train_transforms)\n",
        "valid_dataset = MILDataset(valid_data, test_transforms)\n",
        "test_dataset  = MILDataset(test_data, test_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=collate_fn, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, collate_fn=collate_fn, shuffle=False)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "TozqQt933jcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definition of MIL Model"
      ],
      "metadata": {
        "id": "Cyeb1-3clLBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MILModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.resnet_layers= torch.nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        self.fc=nn.Linear(512,1)\n",
        "\n",
        "        self.fc1=nn.Linear(4,2)\n",
        "        self.fc2=nn.Linear(2,1)\n",
        "        self.relu=nn.ReLU()\n",
        "\n",
        "    def forward(self, images, clinical, indices_of_bags, indices_in_bags):\n",
        "        features = []\n",
        "        start_batch = 0\n",
        "        while start_batch < images.shape[0]:\n",
        "          end_batch = min(start_batch+100, images.shape[0])\n",
        "          features.append(self.resnet_layers(images[start_batch:end_batch]))\n",
        "          start_batch = end_batch\n",
        "        features = torch.cat(features, 0)\n",
        "\n",
        "\n",
        "        indices_bags = indices_of_bags.max() + 1\n",
        "        max_len_bags = indices_in_bags.max() + 1\n",
        "        features=features.view(features.shape[0],-1)\n",
        "        embeddings=torch.zeros(indices_bags, max_len_bags, *features.shape[1:], device=features.device)\n",
        "        embeddings[indices_of_bags, indices_in_bags]=features\n",
        "        weights= torch.zeros(indices_bags, max_len_bags, device=features.device, dtype=torch.long)\n",
        "        weights[indices_of_bags, indices_in_bags] = 1\n",
        "        weights=1/torch.sum(weights, dim=1, keepdim=True)\n",
        "        weights.reshape(indices_bags,1)\n",
        "        embeddings=torch.sum(embeddings, dim=1)*weights\n",
        "        output=self.fc(embeddings)\n",
        "\n",
        "        output2=self.fc2(self.relu(self.fc1(clinical)))\n",
        "\n",
        "        return output.view(-1), output2.view(-1)"
      ],
      "metadata": {
        "id": "Gx4nS3Jx-V5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training of the model"
      ],
      "metadata": {
        "id": "GlT3zG0dlSkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following functions can be used to train, evaluate and save the model."
      ],
      "metadata": {
        "id": "pIYlyPPVlURX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, valid_loader, loss_function, clinical_att):\n",
        "  with torch.no_grad():\n",
        "      validation_loss = 0.0\n",
        "      validation_accuracy = 0.0\n",
        "      number_samples = 0\n",
        "      validation_proba = []\n",
        "      validation_labels = []\n",
        "\n",
        "      for i, batch in enumerate(valid_loader):\n",
        "        images, clinical, labels, indices_of_bags, indices_in_bags = batch\n",
        "        labels = labels.to(device)\n",
        "        outputs1, outputs2 = model(images.to(device), clinical.to(device), indices_of_bags.to(device), indices_in_bags.to(device))\n",
        "        outputs= (outputs1+outputs2)/2 if clinical_att else outputs1\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss = loss.sum()\n",
        "        batch_proba = outputs.sigmoid()\n",
        "        batch_predictions = (batch_proba > 0.5).long()\n",
        "        validation_loss += float(loss)\n",
        "        validation_accuracy += float((batch_predictions == labels).float().sum())\n",
        "        number_samples += float(len(labels))\n",
        "        validation_labels.append(labels.cpu())\n",
        "        validation_proba.append(batch_proba.cpu())\n",
        "\n",
        "      validation_proba = torch.cat(validation_proba, 0)\n",
        "      validation_labels = torch.cat(validation_labels, 0)\n",
        "      bal_accuracy = balanced_accuracy_score(validation_labels, validation_proba > 0.5)\n",
        "      validation_loss = validation_loss/number_samples\n",
        "      validation_accuracy = validation_accuracy/number_samples\n",
        "  return validation_loss, validation_accuracy, bal_accuracy\n",
        "\n",
        "def save_model(model, optimizer):\n",
        "  files = os.listdir('./')\n",
        "  for file in files:\n",
        "      if file.endswith('best_model.pth'):\n",
        "          os.remove(os.path.join('./', file))\n",
        "\n",
        "  torch.save({'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()},\n",
        "              'best_model.pth')\n",
        "\n",
        "  print(\"Saved Best Model\")\n",
        "  return\n",
        "\n",
        "def BCEwithlogits(outputs, labels):\n",
        "  return F.binary_cross_entropy_with_logits(outputs, labels.float(), reduction='none')\n",
        "\n",
        "def DiceLoss(outputs, targets):\n",
        "  function=smp.losses.DiceLoss(mode='binary')\n",
        "  return function(outputs.view(-1,1), targets.view(-1,1))\n",
        "\n",
        "def training(model, trainloader, validloader,epochs, optimizer, scheduler=None, loss_function=BCEwithlogits, clinical_att=False):\n",
        "\n",
        "    best_validation_balanced_accuracy=0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_accuracy = 0.0\n",
        "        number_samples = 0\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        for i, batch in enumerate(trainloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            images, clinical, labels, indices_of_bags, indices_in_bags = batch\n",
        "            labels = labels.to(device)\n",
        "            outputs1, outputs2 = model(images.to(device), clinical.to(device), indices_of_bags.to(device), indices_in_bags.to(device))\n",
        "            outputs= (outputs1+outputs2)/2 if clinical_att else outputs1\n",
        "            loss1 = loss_function(outputs1, labels)\n",
        "            loss2 = loss_function(outputs2, labels)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            batch_proba = outputs.sigmoid()\n",
        "            batch_predictions = (batch_proba > 0.5).long()\n",
        "            mean_loss = (loss1.sum() + loss2.sum())/len(labels) if clinical_att else loss.sum()/len(labels)\n",
        "            mean_loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.sum().item()\n",
        "            epoch_accuracy += (batch_predictions == labels).float().sum().item()\n",
        "            number_samples += len(labels)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss = epoch_loss/number_samples\n",
        "        epoch_accuracy = epoch_accuracy/number_samples\n",
        "        print(f'Epoch {epoch+1}: training loss {epoch_loss:.4f}, training accuracy {epoch_accuracy:.4f}')\n",
        "\n",
        "        #validation\n",
        "        validation_loss, validation_accuracy, bal_accuracy = validation(model, validloader, loss_function, clinical_att)\n",
        "        print(f'Validation accuracy {validation_accuracy:.4f}, loss {validation_loss:.4f}, balanced accuracy {bal_accuracy:.4f}\\n')\n",
        "\n",
        "        #save model\n",
        "        if bal_accuracy>best_validation_balanced_accuracy:\n",
        "            best_validation_balanced_accuracy=bal_accuracy\n",
        "            save_model(model,optimizer)\n",
        "\n",
        "    print('End OF Training')\n"
      ],
      "metadata": {
        "id": "8mSn5IUMIs4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We train a new model with the following hyperparameters."
      ],
      "metadata": {
        "id": "iyqIaaVzlizL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "model = MILModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "training(model, train_loader, valid_loader, 30, optimizer) #, loss_function=DiceLoss, scheduler)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
        "training(model, train_loader, valid_loader, 10, optimizer)"
      ],
      "metadata": {
        "id": "iSJpzakR0vQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write Kaggle submission"
      ],
      "metadata": {
        "id": "D6sCPdqGlotL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the best model and write the submission for Kaggle."
      ],
      "metadata": {
        "id": "Q498z_rElrxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path= './best_model.pth'\n",
        "print('Loading best model')\n",
        "checkpoint = torch.load(path)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "print('writing submission')\n",
        "model.eval()\n",
        "test_proba = []\n",
        "test_predictions = []\n",
        "\n",
        "clinical_att=False\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(tqdm(test_loader)):\n",
        "        images, clinical, labels, indices_of_bags, indices_in_bags = batch\n",
        "        outputs1, outputs2 = model(images.to(device), clinical.to(device), indices_of_bags.to(device), indices_in_bags.to(device))\n",
        "        outputs=(outputs1+outputs2)/2 if clinical_att else outputs1\n",
        "        proba = outputs.sigmoid().cpu()\n",
        "        test_proba.append(proba)\n",
        "\n",
        "test_proba = torch.cat(test_proba, 0)\n",
        "test_predictions = test_proba > 0.5\n",
        "\n",
        "\n",
        "with open('submission12.csv', 'w') as f:\n",
        "    f.write('ID,Predicted\\n')\n",
        "    for ID, pred in zip(test_IDs, test_predictions):\n",
        "        f.write(f'{ID},{pred.int().item()}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJFD7BdLY44m",
        "outputId": "9552c190-0a4c-4f21-80c0-e01684c5cf99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model\n",
            "writing submission\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:03<00:00,  1.14s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2"
      ],
      "metadata": {
        "id": "F6sCZwayrPAH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "P5FO-tL0GIiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annot=directory_dataset+ 'clinical_annotation.csv'\n",
        "annotations=pd.read_csv(annot)\n",
        "annotations['GENDER']=annotations['GENDER'].replace({'M': 0.0, 'F': 1.0, 'f':1.0})\n",
        "#change the format of DOB\n",
        "for i in range(len(annotations)):\n",
        "    dob=annotations.at[i, 'DOB']\n",
        "    if '-' in dob:\n",
        "        parts = dob.split('-')\n",
        "        annotations.at[i, 'DOB']= parts[1] + '/' + parts[0] + '/' + parts[2]\n",
        "\n",
        "#add an age column\n",
        "annotations['DOB'] = pd.to_datetime(annotations['DOB'], format='%m/%d/%Y')\n",
        "date_actuelle = datetime.now()\n",
        "annotations['Age'] = date_actuelle.year - annotations['DOB'].dt.year\n",
        "train_dir=directory_dataset+'trainset'\n",
        "test_dir=directory_dataset+'testset'\n",
        "\n",
        "#charge the name files\n",
        "def files_name(dir):\n",
        "    names = []\n",
        "    for name in os.listdir(dir):\n",
        "        if os.path.isdir(os.path.join(dir, name)):\n",
        "            names.append(name)\n",
        "    return names\n",
        "train_names=files_name(train_dir)\n",
        "test_names=files_name(test_dir)\n",
        "\n",
        "test_df =annotations.loc[(annotations['LABEL'] == -1)]\n",
        "test_df=test_df.reset_index(drop = True)\n",
        "train_df_t0=annotations.loc[(annotations['LABEL'] == 0)]\n",
        "train_df_t1=annotations.loc[(annotations['LABEL'] == 1)]\n",
        "val_size = 0.2\n",
        "train_df0, val_df0 = train_test_split(train_df_t0, test_size=val_size, random_state=42)\n",
        "train_df1, val_df1 = train_test_split(train_df_t1, test_size=val_size, random_state=42)\n",
        "train_df = pd.concat([train_df0, train_df1], ignore_index=True)\n",
        "val_df = pd.concat([val_df0, val_df1], ignore_index=True)"
      ],
      "metadata": {
        "id": "tX_tqr3JrONy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check that we have the same proportion in both training and validation set\n",
        "count_zero_labels = (train_df['LABEL'] == 0).sum()\n",
        "count_ones_labels = (train_df['LABEL'] == 1).sum()\n",
        "print(\"Nombre de valeurs égales à 0 dans train_df['LABEL'] :\", count_zero_labels)\n",
        "print(\"Nombre de valeurs égales à 0 dans train_df['LABEL'] :\", count_ones_labels)\n",
        "count_zero_labels = (val_df['LABEL'] == 0).sum()\n",
        "count_ones_labels = (val_df['LABEL'] == 1).sum()\n",
        "print(\"Nombre de valeurs égales à 0 dans train_df['LABEL'] :\", count_zero_labels)\n",
        "print(\"Nombre de valeurs égales à 0 dans train_df['LABEL'] :\", count_ones_labels)"
      ],
      "metadata": {
        "id": "5qzLPurLrOLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_age=train_df['Age'].mean()\n",
        "std_age=train_df['Age'].mean()\n",
        "mean_ct=train_df['LYMPH_COUNT'].mean()\n",
        "std_ct=train_df['LYMPH_COUNT'].mean()\n",
        "class PatientDataset(Dataset):\n",
        "    def __init__(self, img_dir, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    def __getitem__(self, idx):\n",
        "        images=[]\n",
        "        patient=self.dataframe.loc[idx,'ID']\n",
        "        target=self.dataframe.loc[idx,'LABEL']\n",
        "        gender = torch.tensor((self.dataframe.loc[idx, 'Age']-mean_age)/std_age)\n",
        "        lymph_count = torch.tensor((self.dataframe.loc[idx, 'LYMPH_COUNT']-mean_ct)/std_ct)\n",
        "        datas=[gender,lymph_count]\n",
        "        files = os.listdir(os.path.join(self.img_dir, patient))\n",
        "        for file in files:\n",
        "            direc = os.path.join(self.img_dir, patient, file)\n",
        "            img = Image.open(direc)\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            images.append(img)\n",
        "        return torch.stack(images),torch.Tensor(datas),torch.tensor(target,dtype=torch.float32 ),patient# des torch.tensor?\n",
        "\n",
        "#transformations to apply on images\n",
        "data_transforms_train = transforms.Compose([\n",
        "    torchvision.transforms.CenterCrop(112),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
        "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "data_transforms_test=transforms.Compose([\n",
        "    torchvision.transforms.CenterCrop(112),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "#charge the dataset into train test and val loader\n",
        "train_dataset=PatientDataset(train_dir,train_df,data_transforms_train)\n",
        "val_dataset=PatientDataset(train_dir,val_df,data_transforms_test)\n",
        "batch_size=1\n",
        "trainloader = DataLoader(train_dataset,batch_size = batch_size,shuffle = True)\n",
        "valloader=DataLoader(val_dataset,batch_size = batch_size,shuffle = True)\n",
        "test_dataset=PatientDataset(test_dir,test_df,data_transforms_test)\n",
        "testloader = DataLoader(test_dataset,batch_size = batch_size,shuffle = True)\n"
      ],
      "metadata": {
        "id": "a220K-V__0yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIL Model"
      ],
      "metadata": {
        "id": "em6cvrbwGzGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
        "from torchvision.models import resnet34,resnet18\n",
        "\n",
        "class resnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(resnet, self).__init__()\n",
        "        self.resnet = resnet18(weights=None)#'DEFAULT')\n",
        "        self.resnet_layers= torch.nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        self.fc=nn.Linear(512,256)\n",
        "        self.fc1=nn.Linear(256,1)\n",
        "\n",
        "    def forward(self, images):\n",
        "\n",
        "        out = self.resnet_layers(images)\n",
        "        out= torch.squeeze(out, axis=2)\n",
        "        out=torch.mean(out, dim=0)\n",
        "        out=torch.flatten(out)\n",
        "        x=nn.ReLU()(self.fc(out))\n",
        "        x=self.fc1(x)\n",
        "        return x\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer1 = nn.Linear(2, 150)\n",
        "        self.layer2 = nn.Linear(150, 250)\n",
        "        self.activation = nn.Sigmoid()\n",
        "        self.layer3 = nn.Linear(250, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.layer1(x))\n",
        "        x = nn.ReLU()(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return  x\n"
      ],
      "metadata": {
        "id": "XEji8VwA_0vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training of the Model"
      ],
      "metadata": {
        "id": "6bkRtSgAHJBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model,valloader,criterion,device='cpu',typet='mlp'):\n",
        "    with torch.no_grad():\n",
        "        validation_loss = 0.0\n",
        "        validation_accuracy = 0.0\n",
        "        for i,  (inputs,datas, targets,_)  in enumerate(valloader):\n",
        "            inputs,datas, targets = inputs.to(device), datas.to(device),targets.to(device)\n",
        "            outputs=[]\n",
        "            if (typet=='mlp'):\n",
        "                outputs = model.forward(datas[0])\n",
        "            if (typet=='res'):\n",
        "                outputs = model.forward(inputs[0])\n",
        "            loss = criterion(outputs, targets)\n",
        "            validation_loss+=loss.item()\n",
        "            predicted=outputs\n",
        "            pred_np=np.where(predicted.detach().cpu().numpy()>0.6,1,0)\n",
        "            validation_accuracy+=accuracy_score(pred_np,targets.detach().cpu().numpy())\n",
        "        print(' Loss_acc : {:.4f}    Balanced Accuracy : {:.4f} %'.format(validation_loss/len(valloader),100*validation_accuracy/len(valloader)))\n",
        "    return validation_loss, validation_accuracy\n",
        "\n",
        "def save_model(model, optimizer,opt='mlp'):\n",
        "    files = os.listdir('./')\n",
        "    for file in files:\n",
        "        if file.endswith('best_model.pth'):\n",
        "            os.remove(os.path.join('./', file))\n",
        "    if(opt=='mlp'):\n",
        "        torch.save({'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()},\n",
        "              'best_model_mlp.pth')\n",
        "    else:\n",
        "        torch.save({'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict()},\n",
        "              'best_model_res.pth')\n",
        "\n",
        "    print(\"Saved Best Model\")\n",
        "    return\n",
        "\n",
        "def train(model,trainloader,valloader,criterion,optimizer,n_epochs,device='cpu',typet='mlp'):\n",
        "    model.train()\n",
        "    train_losses=[]\n",
        "    train_acc=[]\n",
        "    print('Start training')\n",
        "    best_validation_balanced_accuracy=0\n",
        "    for epoch in range(0,n_epochs):\n",
        "        t_loss=0\n",
        "        acc=0\n",
        "        bacc=0\n",
        "        for batch_idx, (inputs,datas, targets,_) in enumerate(trainloader):\n",
        "            inputs,datas, targets = inputs.to(device), datas.to(device),targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs=[]\n",
        "            if (typet=='mlp'):\n",
        "                outputs = model.forward(datas[0])\n",
        "            if (typet=='res'):\n",
        "                outputs = model.forward(inputs[0])\n",
        "\n",
        "            loss=criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            t_loss+=loss.item()\n",
        "\n",
        "            predicted=outputs\n",
        "            pred_np=np.where(predicted.detach().cpu().numpy()>0.5,1,0)\n",
        "            bacc+=accuracy_score(pred_np,targets.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "        train_losses.append(t_loss/len(trainloader))\n",
        "        if epoch % 1 == 0  :\n",
        "            print(' Epoch: {} : Loss_bag : {:.4f}  Balanced Accuracy : {:.4f} %'.format(epoch,t_loss/len(trainloader),100*bacc/len(trainloader)))\n",
        "\n",
        "        validation_loss, validation_accuracy=validation(model,valloader,criterion,device=device,typet=typet)\n",
        "                #save model\n",
        "        if validation_accuracy>best_validation_balanced_accuracy:\n",
        "            best_validation_balanced_accuracy=validation_accuracy\n",
        "            save_model(model,optimizer,opt=typet)\n",
        "    #print(' Epoch: {} : Loss_bag : {:.4f}    Accuracy : {:.4f} Balanced Accuracy : {:.4f} %'.format(epoch, t_loss/len(trainloader),100*acc/len(trainloader),100*bacc/len(trainloader)))\n",
        "    return train_losses,train_acc\n"
      ],
      "metadata": {
        "id": "je8H_omjHLOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda'\n",
        "k=8\n",
        "model_mlp=MLP().to(device)\n",
        "model_res=resnet().to(device)\n",
        "learning_rate=1e-4\n",
        "w_decay=5e-4\n",
        "criterion = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "i2qmeFqQHLLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=1e-4\n",
        "w_decay=5e-4\n",
        "optimizer_res = torch.optim.Adam(model_res.parameters(), lr=learning_rate, weight_decay=w_decay)\n",
        "lr_scheduler_res = torch.optim.lr_scheduler.StepLR(optimizer_res, step_size=10, gamma=0.1)\n",
        "n_epochs=80\n",
        "train(model_res,trainloader,valloader,criterion,optimizer_res,n_epochs,device=device,typet='res')"
      ],
      "metadata": {
        "id": "pLvnsNp2HLH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MB-lmS6JqFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate=1e-4\n",
        "w_decay=5e-4\n",
        "optimizer_mlp = torch.optim.Adam(model_mlp.parameters(), lr=learning_rate, weight_decay=w_decay)\n",
        "lr_scheduler_mlp = torch.optim.lr_scheduler.StepLR(optimizer_mlp, step_size=100, gamma=0.1)\n",
        "\n",
        "n_epochs=60\n",
        "train(model_mlp,trainloader,valloader,criterion,optimizer_mlp,n_epochs,device=device,typet='mlp')"
      ],
      "metadata": {
        "id": "Q8-KbkOZ_0ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and submission file"
      ],
      "metadata": {
        "id": "6vUfK88VLOwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading best model')\n",
        "dir_out='/kaggle/working/'\n",
        "checkpoint = torch.load(dir_out+'/best_model_mlp.pth')\n",
        "model_mlp.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "D5I0EDlvKod1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loading best model')\n",
        "dir_out='/kaggle/working/'\n",
        "checkpoint = torch.load(dir_out+'/best_model_res.pth')\n",
        "model_res.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "mHd1WwTAKobF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds={}\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (inputs,datas, targets,patient) in enumerate(testloader):\n",
        "        inputs,datas, targets = inputs.to(device), datas.to(device),targets.to(device)\n",
        "        outputs_ft= model_res.forward(inputs[0])\n",
        "        outputs_bag = model_mlp.forward(datas[0])\n",
        "        predicted=(outputs_bag+outputs_ft)/2\n",
        "        pred_np=np.where(predicted.detach().cpu().numpy()>0.5,1.0,0.0)\n",
        "        preds[patient[0]]=int(pred_np[0] )\n",
        "preds"
      ],
      "metadata": {
        "id": "4j9qzAZYKoYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.DataFrame.from_dict(preds, orient='index', columns=['Predicted'])\n",
        "dataframe.reset_index(inplace=True)\n",
        "dataframe.rename(columns={'index': 'ID'}, inplace=True)\n",
        "dataframe.to_csv('submission_only_mlp8.csv', index=False)\n",
        "print(dataframe.head())"
      ],
      "metadata": {
        "id": "wrQxgMigKoVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUg9_v4iKoSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mgjO1NabKoPU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}